%!TEX root = ../main.tex
\section{Benchmark Design} 
In this section, we first introduce the design goals of \sys benchmark for table discovery tasks, and then present how to generate the \sys benchmark consisting of datasets, queries and ground truth.

\subsection{Design Goals}
We design the table discovery benchmark by the 
benchmark design criteria proposed by Jim Gray.

\noindent\textbf{Relevance.}
The benchmark covers a wide range of table discovery characteristics. First, in terms of the data lake, we incorporate 4 lakes with size ranging from 10GB to 1TB, and with column number ranging from \cc{1 million} to 10 million. Second, in terms of the queries, with the help of much human efforts, we create and label more than 10 thousand table queries that cover various query characteristics, including column semantic, column overlapping, column size, etc.



\noindent\textbf{Scalability.} The benchmark involves much larger data lakes than existing data lakes for table discovery. The data lake size should be considered from two aspects. One is the normal total storage size that is highly related  to the average table size  and the number of tables. The other is the number of total columns because almost all table discovery algorithms build index and search over a large number of columns.  \sys involves up to 1 TB data lake and 10 million columns, which is sufficient enough to evaluate the scalability.




\noindent\textbf{Simplicity} The benchmark 









\subsection{Benchmark Overview}


\noindent\textbf{Datasets}
We collect three datasets from OpenData~\cite{OpenData}, WebTable~\cite{WebTable}. 

\cc{Introduce what here? Should avoid repetition with next Section.}

+ Statistics of collected datasets.

+ Clean the datasets.

+ Remove sth.

%Table~\ref{table} summarizes the statistics of collected datasets.


\noindent\textbf{Query Generation}

+ Fake tables: split-based. Split large tables into small ones, which are put into the data lake, and then use some of the small ones as queries.

+ Real tables: retrieved-based. Use real tables as query tables, and directly query the data lake.


+ Classify: 

\quad\quad -- Column type (string, number, category)
 
\quad\quad -- Fake or real
  
\quad\quad -- Selectivity

\quad\quad -- Size

\noindent\textbf{Ground Truth Creation}

+ Semi-automatic label: corresponding to fake tables. Some positive results are automatically generated, while others should be manually labeled.

+ Manually label: corresponding to real tables.

\noindent\textbf{Method Evaluation} \cc{How to category}



    \begin{table*}[t]
        \centering
        \caption{Table Discovery Methods.}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \centering
            Methods & Task & Index Type & Embedding & KB  \\
            \hline
            Josie~\cite{Josie} & Join & Inverted index & \XSolidBrush & \XSolidBrush  \\
            \hline
            LSH Ensemble~\cite{LshEn} & Join & LSH & \XSolidBrush & \XSolidBrush  \\
            \hline
            Pexeso~\cite{Pexeso} & Join &  Inverted index, Hierarchical gird & \Checkmark & \XSolidBrush  \\
            \hline
            DeepJoin~\cite{DeepJoin} & Join & HNSW & \Checkmark & \XSolidBrush  \\
            \hline
             TUS~\cite{TUS} & Union & LSH & \Checkmark & \Checkmark  \\
            \hline
            D3L~\cite{D3L} & Union & LSH & \Checkmark & \XSolidBrush  \\
            \hline
            Starmie~\cite{Starmie} & Union & HNSW & \Checkmark & \XSolidBrush  \\
            \hline
            Santos~\cite{Santos} & Union & Inverted index & \XSolidBrush & \Checkmark  \\
            \hline
            Frt12~\cite{Frt12} & Join \& Union & \XSolidBrush & \XSolidBrush & \Checkmark  \\
            \hline
            InfoGather~\cite{InfoGather} & Join \& Union & Inverted index & \XSolidBrush & \XSolidBrush  \\
            \hline
            Aurum~\cite{Aurum} & Join \& Union & LSH & \Checkmark & \XSolidBrush  \\
            \hline
        \end{tabular}
        \label{table:methods}
        
    \end{table*}

+ \cc{Join/Union}

+ \cc{Schema matching}

+ Hash-based

+ Inverted index 

+ Pre-trained language model (HNSW)


\noindent\textbf{API Design}

